{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a587811c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dependencies and setup\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from sklearn import metrics\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "81f7e9f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# File to load\n",
    "to_load = Path(\"cancer_patient_datasets.csv\")\n",
    "# Create the dataframe\n",
    "nn_df = pd.read_csv(to_load)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a32f038d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop unnecessary columns index and Patient Id\n",
    "nn_df = nn_df.drop(columns=['index', 'Patient Id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "515b4f88",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert low, medium, high to numeric\n",
    "nn_df.Level = nn_df.Level.replace(\"Low\", 0)\n",
    "nn_df.Level = nn_df.Level.replace(\"Medium\", 1)\n",
    "nn_df.Level = nn_df.Level.replace(\"High\", 2)\n",
    "\n",
    "nn_df.Level = nn_df.Level.astype(\"int64\")\n",
    "# create target and features array\n",
    "X = nn_df.drop(\"Level\", axis = 1)\n",
    "y = pd.get_dummies(nn_df[\"Level\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3a4caaa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the preprocessed data into a training and testing dataset\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=78)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f1d294c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a StandardScaler instances\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Fit the StandardScaler\n",
    "X_scaler = scaler.fit(X_train)\n",
    "\n",
    "# Scale the data\n",
    "X_train_scaled = X_scaler.transform(X_train)\n",
    "X_test_scaled = X_scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "96a62652",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def create_model(hp):\n",
    "    nn_model = tf.keras.models.Sequential()\n",
    "    \n",
    "    # Correctly setting up the choice for activation functions\n",
    "    activation = hp.Choice('activation', ['relu', 'tanh', 'sigmoid'])\n",
    "    \n",
    "    # Correcting the input shape parameter\n",
    "    nn_model.add(tf.keras.layers.Dense(\n",
    "        units=hp.Int('first_units', min_value=1, max_value=128, step=32),\n",
    "        activation=activation, \n",
    "        input_shape=(23,)\n",
    "    ))\n",
    "    \n",
    "    # Adding a range for the number of additional layers\n",
    "    for i in range(hp.Int('num_layers', 1, 6)):\n",
    "        nn_model.add(tf.keras.layers.Dense(\n",
    "            units=hp.Int('units_' + str(i), min_value=1, max_value=128, step=32),\n",
    "            activation=activation\n",
    "        ))\n",
    "    \n",
    "    # Assuming 3 classes in the output layer\n",
    "    nn_model.add(tf.keras.layers.Dense(units=3, activation=\"softmax\"))\n",
    "    nn_model.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
    "    return nn_model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f7455be4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reloading Tuner from hyperband\\cancer_classification\\tuner0.json\n",
      "Search space summary\n",
      "Default search space size: 9\n",
      "activation (Choice)\n",
      "{'default': 'relu', 'conditions': [], 'values': ['relu', 'tanh', 'sigmoid'], 'ordered': False}\n",
      "first_units (Int)\n",
      "{'default': None, 'conditions': [], 'min_value': 1, 'max_value': 128, 'step': 32, 'sampling': 'linear'}\n",
      "num_layers (Int)\n",
      "{'default': None, 'conditions': [], 'min_value': 1, 'max_value': 6, 'step': 1, 'sampling': 'linear'}\n",
      "units_0 (Int)\n",
      "{'default': None, 'conditions': [], 'min_value': 1, 'max_value': 128, 'step': 32, 'sampling': 'linear'}\n",
      "units_1 (Int)\n",
      "{'default': None, 'conditions': [], 'min_value': 1, 'max_value': 128, 'step': 32, 'sampling': 'linear'}\n",
      "units_2 (Int)\n",
      "{'default': None, 'conditions': [], 'min_value': 1, 'max_value': 128, 'step': 32, 'sampling': 'linear'}\n",
      "units_3 (Int)\n",
      "{'default': None, 'conditions': [], 'min_value': 1, 'max_value': 128, 'step': 32, 'sampling': 'linear'}\n",
      "units_4 (Int)\n",
      "{'default': None, 'conditions': [], 'min_value': 1, 'max_value': 128, 'step': 32, 'sampling': 'linear'}\n",
      "units_5 (Int)\n",
      "{'default': None, 'conditions': [], 'min_value': 1, 'max_value': 128, 'step': 32, 'sampling': 'linear'}\n"
     ]
    }
   ],
   "source": [
    "from keras_tuner import Hyperband, Objective\n",
    "\n",
    "tuner = Hyperband(\n",
    "    create_model,\n",
    "    objective=Objective(\"val_accuracy\", direction=\"max\"),\n",
    "    max_epochs=100,\n",
    "    hyperband_iterations=2,\n",
    "    directory='hyperband',\n",
    "    project_name='cancer_classification'\n",
    ")\n",
    "tuner.search_space_summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3570cef1",
   "metadata": {},
   "outputs": [],
   "source": [
    "tuner.search(X_train, y_train, epochs=10, validation_data=(X_test_scaled, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "dd788ff6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'activation': 'relu',\n",
       " 'first_units': 65,\n",
       " 'num_layers': 1,\n",
       " 'units_0': 97,\n",
       " 'units_1': 65,\n",
       " 'units_2': 65,\n",
       " 'units_3': 97,\n",
       " 'units_4': 65,\n",
       " 'units_5': 97,\n",
       " 'tuner/epochs': 34,\n",
       " 'tuner/initial_epoch': 12,\n",
       " 'tuner/bracket': 4,\n",
       " 'tuner/round': 3,\n",
       " 'tuner/trial_id': '0392'}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_hyper = tuner.get_best_hyperparameters(1)[0]\n",
    "best_hyper.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e6aab7f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\GamingPC\\anaconda3\\Lib\\site-packages\\keras\\src\\backend\\common\\global_state.py:82: The name tf.reset_default_graph is deprecated. Please use tf.compat.v1.reset_default_graph instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\GamingPC\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
      "C:\\Users\\GamingPC\\anaconda3\\Lib\\site-packages\\keras_tuner\\src\\tuners\\hyperband.py:435: UserWarning: Model 'sequential' had a build config, but the model cannot be built automatically in `build_from_config(config)`. You should implement `def build_from_config(self, config)`, and you might also want to implement the method  that generates the config at saving time, `def get_build_config(self)`. The method `build_from_config()` is meant to create the state of the model (i.e. its variables) upon deserialization.\n",
      "  model.build_from_config(\n",
      "C:\\Users\\GamingPC\\anaconda3\\Lib\\site-packages\\keras\\src\\saving\\saving_lib.py:415: UserWarning: Skipping variable loading for optimizer 'adam', because it has 2 variables whereas the saved optimizer has 14 variables. \n",
      "  saveable.load_own_variables(weights_store.get(inner_path))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 0.0232  \n",
      "Loss: 0.021024776622653008\n",
      "Accuracy: 1.0\n"
     ]
    }
   ],
   "source": [
    "best_model = tuner.get_best_models(num_models=1)[0]\n",
    "\n",
    "# Evaluate the best model\n",
    "loss, accuracy = best_model.evaluate(X_test, y_test)\n",
    "print(\"Loss:\", loss)\n",
    "print(\"Accuracy:\", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0a32476b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/34\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\GamingPC\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\core\\input_layer.py:25: UserWarning: Argument `input_shape` is deprecated. Use `shape` instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24/24 - 1s - 28ms/step - accuracy: 0.6147 - loss: 0.8047 - val_accuracy: 0.8080 - val_loss: 0.5493\n",
      "Epoch 2/34\n",
      "24/24 - 0s - 2ms/step - accuracy: 0.8893 - loss: 0.4186 - val_accuracy: 0.9120 - val_loss: 0.3402\n",
      "Epoch 3/34\n",
      "24/24 - 0s - 2ms/step - accuracy: 0.9413 - loss: 0.2709 - val_accuracy: 0.9640 - val_loss: 0.2398\n",
      "Epoch 4/34\n",
      "24/24 - 0s - 2ms/step - accuracy: 0.9587 - loss: 0.1989 - val_accuracy: 0.9640 - val_loss: 0.1828\n",
      "Epoch 5/34\n",
      "24/24 - 0s - 2ms/step - accuracy: 0.9587 - loss: 0.1546 - val_accuracy: 0.9640 - val_loss: 0.1449\n",
      "Epoch 6/34\n",
      "24/24 - 0s - 2ms/step - accuracy: 0.9707 - loss: 0.1240 - val_accuracy: 0.9920 - val_loss: 0.1172\n",
      "Epoch 7/34\n",
      "24/24 - 0s - 2ms/step - accuracy: 0.9893 - loss: 0.1012 - val_accuracy: 0.9920 - val_loss: 0.0960\n",
      "Epoch 8/34\n",
      "24/24 - 0s - 2ms/step - accuracy: 0.9893 - loss: 0.0833 - val_accuracy: 0.9920 - val_loss: 0.0795\n",
      "Epoch 9/34\n",
      "24/24 - 0s - 2ms/step - accuracy: 0.9893 - loss: 0.0696 - val_accuracy: 1.0000 - val_loss: 0.0669\n",
      "Epoch 10/34\n",
      "24/24 - 0s - 2ms/step - accuracy: 1.0000 - loss: 0.0581 - val_accuracy: 1.0000 - val_loss: 0.0559\n",
      "Epoch 11/34\n",
      "24/24 - 0s - 2ms/step - accuracy: 1.0000 - loss: 0.0488 - val_accuracy: 1.0000 - val_loss: 0.0475\n",
      "Epoch 12/34\n",
      "24/24 - 0s - 2ms/step - accuracy: 1.0000 - loss: 0.0415 - val_accuracy: 1.0000 - val_loss: 0.0400\n",
      "Epoch 13/34\n",
      "24/24 - 0s - 2ms/step - accuracy: 1.0000 - loss: 0.0352 - val_accuracy: 1.0000 - val_loss: 0.0344\n",
      "Epoch 14/34\n",
      "24/24 - 0s - 2ms/step - accuracy: 1.0000 - loss: 0.0302 - val_accuracy: 1.0000 - val_loss: 0.0299\n",
      "Epoch 15/34\n",
      "24/24 - 0s - 2ms/step - accuracy: 1.0000 - loss: 0.0262 - val_accuracy: 1.0000 - val_loss: 0.0261\n",
      "Epoch 16/34\n",
      "24/24 - 0s - 2ms/step - accuracy: 1.0000 - loss: 0.0229 - val_accuracy: 1.0000 - val_loss: 0.0228\n",
      "Epoch 17/34\n",
      "24/24 - 0s - 2ms/step - accuracy: 1.0000 - loss: 0.0201 - val_accuracy: 1.0000 - val_loss: 0.0201\n",
      "Epoch 18/34\n",
      "24/24 - 0s - 2ms/step - accuracy: 1.0000 - loss: 0.0178 - val_accuracy: 1.0000 - val_loss: 0.0177\n",
      "Epoch 19/34\n",
      "24/24 - 0s - 2ms/step - accuracy: 1.0000 - loss: 0.0158 - val_accuracy: 1.0000 - val_loss: 0.0159\n",
      "Epoch 20/34\n",
      "24/24 - 0s - 2ms/step - accuracy: 1.0000 - loss: 0.0141 - val_accuracy: 1.0000 - val_loss: 0.0143\n",
      "Epoch 21/34\n",
      "24/24 - 0s - 2ms/step - accuracy: 1.0000 - loss: 0.0127 - val_accuracy: 1.0000 - val_loss: 0.0128\n",
      "Epoch 22/34\n",
      "24/24 - 0s - 2ms/step - accuracy: 1.0000 - loss: 0.0114 - val_accuracy: 1.0000 - val_loss: 0.0116\n",
      "Epoch 23/34\n",
      "24/24 - 0s - 2ms/step - accuracy: 1.0000 - loss: 0.0104 - val_accuracy: 1.0000 - val_loss: 0.0105\n",
      "Epoch 24/34\n",
      "24/24 - 0s - 2ms/step - accuracy: 1.0000 - loss: 0.0094 - val_accuracy: 1.0000 - val_loss: 0.0096\n",
      "Epoch 25/34\n",
      "24/24 - 0s - 2ms/step - accuracy: 1.0000 - loss: 0.0086 - val_accuracy: 1.0000 - val_loss: 0.0088\n",
      "Epoch 26/34\n",
      "24/24 - 0s - 2ms/step - accuracy: 1.0000 - loss: 0.0079 - val_accuracy: 1.0000 - val_loss: 0.0080\n",
      "Epoch 27/34\n",
      "24/24 - 0s - 2ms/step - accuracy: 1.0000 - loss: 0.0072 - val_accuracy: 1.0000 - val_loss: 0.0074\n",
      "Epoch 28/34\n",
      "24/24 - 0s - 2ms/step - accuracy: 1.0000 - loss: 0.0067 - val_accuracy: 1.0000 - val_loss: 0.0069\n",
      "Epoch 29/34\n",
      "24/24 - 0s - 2ms/step - accuracy: 1.0000 - loss: 0.0062 - val_accuracy: 1.0000 - val_loss: 0.0064\n",
      "Epoch 30/34\n",
      "24/24 - 0s - 2ms/step - accuracy: 1.0000 - loss: 0.0057 - val_accuracy: 1.0000 - val_loss: 0.0059\n",
      "Epoch 31/34\n",
      "24/24 - 0s - 2ms/step - accuracy: 1.0000 - loss: 0.0053 - val_accuracy: 1.0000 - val_loss: 0.0055\n",
      "Epoch 32/34\n",
      "24/24 - 0s - 2ms/step - accuracy: 1.0000 - loss: 0.0050 - val_accuracy: 1.0000 - val_loss: 0.0052\n",
      "Epoch 33/34\n",
      "24/24 - 0s - 2ms/step - accuracy: 1.0000 - loss: 0.0046 - val_accuracy: 1.0000 - val_loss: 0.0048\n",
      "Epoch 34/34\n",
      "24/24 - 0s - 2ms/step - accuracy: 1.0000 - loss: 0.0043 - val_accuracy: 1.0000 - val_loss: 0.0045\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x20e205f2d50>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define the model - deep neural net, i.e., the number of input features and hidden nodes for each layer.\n",
    "model = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.InputLayer(input_shape=(23,)),  # Assuming 23 input features\n",
    "    tf.keras.layers.Dense(65, activation='relu'),  # First dense layer with 65 units\n",
    "      # Assuming using more layers as per 'units_0' to 'units_5'\n",
    "    tf.keras.layers.Dense(3, activation='softmax')  # Output layer for 3 classes\n",
    "])\n",
    "model.compile(\n",
    "    optimizer='adam',\n",
    "    loss='categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "model.fit(X_train_scaled,y_train, epochs=34, validation_data=(X_test_scaled,y_test),verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1657195a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    }
   ],
   "source": [
    "model.save('Optimised_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd304f89",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "589e54f7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "391bc76d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9161598c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    }
   ],
   "source": [
    "# Export our model to HDF5 file\n",
    "# Define the file path for saving the model\n",
    "filepath = \"LungCancer.h5\"\n",
    "\n",
    "# Save the model to HDF5 format\n",
    "model.save(filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "375a23af",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
